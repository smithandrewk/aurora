{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Get Data\n",
    "The following code block allows a user to get data files and utility scripts beginning with only main.ipynb either locally or on Google Colab."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "wget import exists\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "from os import path\n",
    "try:\n",
    "    __import__(\"wget\")\n",
    "    import wget\n",
    "    print(\"wget import exists\")\n",
    "    if(not path.exists(\"data\")):\n",
    "        print(\"Making Directory data\")\n",
    "        os.mkdir(\"data\")   \n",
    "    if(not path.exists(\"data/control.xls\")):\n",
    "        print(\"Downloading control.xls\")\n",
    "        wget.download(\"https://raw.githubusercontent.com/smithandrewk/sleep/main/data/control.xls\",\"data/control.xls\")\n",
    "    if(not path.exists(\"data/deprivation.xls\")):\n",
    "        print(\"Downloading deprivation.xls\")\n",
    "        wget.download(\"https://raw.githubusercontent.com/smithandrewk/sleep/main/data/deprivation.xls\",\"data/deprivation.xls\")\n",
    "    if(not path.exists(\"scripts\")):\n",
    "        print(\"Making Directory scripts\")\n",
    "        os.mkdir(\"scripts\")   \n",
    "    if(not path.exists(\"scripts/utils.py\")):\n",
    "        print(\"Downloading utils.py\")\n",
    "        wget.download(\"https://raw.githubusercontent.com/smithandrewk/sleep/main/scripts/utils.py\",\"scripts/utils.py\")\n",
    "except ImportError:\n",
    "    print(\"wget import does not exist, using python2.7 wget\")\n",
    "    if(not path.exists(\"data\")):\n",
    "        print(\"Making Directory data\")\n",
    "        !mkdir data   \n",
    "    if(not path.exists(\"data/control.xls\")):\n",
    "        print(\"control.xls not in data\")\n",
    "        !wget -O data/control.xls https://raw.githubusercontent.com/smithandrewk/sleep/main/data/control.xls\n",
    "    if(not path.exists(\"data/deprivation.xls\")):\n",
    "        print(\"deprivation.xls not in data\")\n",
    "        !wget -O data/deprivation.xls https://raw.githubusercontent.com/smithandrewk/sleep/main/data/deprivation.xls\n",
    "    if(not path.exists(\"scripts\")):\n",
    "        print(\"Making Directory scripts\")\n",
    "        !mkdir scripts\n",
    "    if(not path.exists(\"scripts/utils.py\")):\n",
    "        !wget -O scripts/utils.py https://raw.githubusercontent.com/smithandrewk/sleep/main/scripts/utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Examples:\n    Total: 8641\n    P: 367 (4.25% of total)\n    S: 3965 (45.89% of total)\n    W: 4309 (49.87% of total)\n\n"
     ]
    }
   ],
   "source": [
    "from scripts.utils import *\n",
    "df = preprocess(\"control\")\n",
    "## Statistics\n",
    "# df.describe() # nice for obtaining statistics over dataframe\n",
    "p,s,w = np.bincount(df['Class'])\n",
    "total = p + s + w\n",
    "print('Examples:\\n    Total: {}\\n    P: {} ({:.2f}% of total)\\n    S: {} ({:.2f}% of total)\\n    W: {} ({:.2f}% of total)\\n'.format(\n",
    "    total, p, 100 * p / total,s,100 * s / total,w,100 * w / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "6270262895"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "ps = df.loc[df[\"Class\"]==0]\n",
    "ss = df.loc[df[\"Class\"]==1]\n",
    "ws = df.loc[df[\"Class\"]==2]\n",
    "ps_lcm = np.lcm(p,s)\n",
    "lcm = np.lcm(ps_lcm,w)\n",
    "lcm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      Class      0-0.5       0.5-1      1-1.5       1.5-2      2-2.5  \\\n",
       "1         2  24.586045   55.131697  78.506117   52.740326  58.563386   \n",
       "2         2  37.074691  128.947192  24.519845   39.892634  27.384148   \n",
       "3         2  54.415625  115.325207  86.279811   79.842617  41.354535   \n",
       "4         2   1.027493    2.622392   8.170351    1.964630   5.602924   \n",
       "5         2   0.000000    0.000000   0.000000    0.000000   0.000000   \n",
       "...     ...        ...         ...        ...         ...        ...   \n",
       "8307      0  58.509531   24.130297  77.456597  119.575308  21.386708   \n",
       "8308      0  18.844414   60.880904  42.080082   99.809994  60.119598   \n",
       "8309      0  55.335973   20.153225  46.843079   63.216221  57.758503   \n",
       "8310      0  28.903322   21.978773  34.023285   69.517689  42.079554   \n",
       "8311      0  20.463551   53.105440  25.725438   86.511128  42.522998   \n",
       "\n",
       "          2.5-3      3-3.5      3.5-4      4-4.5  ...    16-16.5   16.5-17  \\\n",
       "1     14.552035  26.364280  21.642888  37.597922  ...   1.330372  2.701623   \n",
       "2     37.036906  26.095708  26.226684  39.873118  ...   1.971869  3.658804   \n",
       "3     57.572824  29.798652  27.533800  12.925224  ...   3.819550  2.731836   \n",
       "4      1.842355   5.649830   3.664765   3.457500  ...   0.478062  0.182575   \n",
       "5      0.000000   0.000000   0.000000   0.000000  ...   0.000000  0.000000   \n",
       "...         ...        ...        ...        ...  ...        ...       ...   \n",
       "8307  25.598958  61.105373  22.656495  24.167232  ...   3.931479  1.968162   \n",
       "8308  74.158525  45.799685  43.245535  37.006743  ...   1.771997  2.485157   \n",
       "8309  32.045904  27.292346  17.916218  16.484902  ...   3.273334  2.513552   \n",
       "8310  68.849285  72.357107  43.558518  33.260433  ...   2.236040  2.790370   \n",
       "8311  25.147855  58.176851  33.713236  45.624965  ...  11.106229  8.483935   \n",
       "\n",
       "       17-17.5   17.5-18   18-18.5    18.5-19   19-19.5   19.5-20  Activity  \\\n",
       "1     2.032272  2.481273  2.769557   2.156247  2.940888  3.470576  0.100994   \n",
       "2     3.343531  1.425610  4.532924   2.431444  3.888520  1.921557  0.200995   \n",
       "3     4.763795  1.898447  2.378209   2.500515  3.305095  2.035448  0.501000   \n",
       "4     0.981841  0.268720  0.039398   0.081701  0.060758  0.125317  1.101009   \n",
       "5     0.000000  0.000000  0.000000   0.000000  0.000000  0.000000  0.200995   \n",
       "...        ...       ...       ...        ...       ...       ...       ...   \n",
       "8307  3.062893  1.562262  2.931484   2.914780  2.472442  4.033660  0.000992   \n",
       "8308  3.483579  3.607862  3.197097   2.469661  2.292118  2.642321  0.100994   \n",
       "8309  2.625054  1.996016  2.268182   3.123659  3.243166  4.084404  0.000992   \n",
       "8310  2.339984  2.798732  3.253075   6.331714  1.341946  2.979213  0.000992   \n",
       "8311  7.629401  8.949675  5.540413  15.168735  7.626594  6.021769  0.000992   \n",
       "\n",
       "         EEG 2  \n",
       "1    -6.294846  \n",
       "2    -2.346836  \n",
       "3     0.920145  \n",
       "4     0.000000  \n",
       "5     0.000000  \n",
       "...        ...  \n",
       "8307  2.001416  \n",
       "8308  0.160058  \n",
       "8309  1.970815  \n",
       "8310  0.134202  \n",
       "8311  0.787857  \n",
       "\n",
       "[12678 rows x 43 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Class</th>\n      <th>0-0.5</th>\n      <th>0.5-1</th>\n      <th>1-1.5</th>\n      <th>1.5-2</th>\n      <th>2-2.5</th>\n      <th>2.5-3</th>\n      <th>3-3.5</th>\n      <th>3.5-4</th>\n      <th>4-4.5</th>\n      <th>...</th>\n      <th>16-16.5</th>\n      <th>16.5-17</th>\n      <th>17-17.5</th>\n      <th>17.5-18</th>\n      <th>18-18.5</th>\n      <th>18.5-19</th>\n      <th>19-19.5</th>\n      <th>19.5-20</th>\n      <th>Activity</th>\n      <th>EEG 2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>24.586045</td>\n      <td>55.131697</td>\n      <td>78.506117</td>\n      <td>52.740326</td>\n      <td>58.563386</td>\n      <td>14.552035</td>\n      <td>26.364280</td>\n      <td>21.642888</td>\n      <td>37.597922</td>\n      <td>...</td>\n      <td>1.330372</td>\n      <td>2.701623</td>\n      <td>2.032272</td>\n      <td>2.481273</td>\n      <td>2.769557</td>\n      <td>2.156247</td>\n      <td>2.940888</td>\n      <td>3.470576</td>\n      <td>0.100994</td>\n      <td>-6.294846</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>37.074691</td>\n      <td>128.947192</td>\n      <td>24.519845</td>\n      <td>39.892634</td>\n      <td>27.384148</td>\n      <td>37.036906</td>\n      <td>26.095708</td>\n      <td>26.226684</td>\n      <td>39.873118</td>\n      <td>...</td>\n      <td>1.971869</td>\n      <td>3.658804</td>\n      <td>3.343531</td>\n      <td>1.425610</td>\n      <td>4.532924</td>\n      <td>2.431444</td>\n      <td>3.888520</td>\n      <td>1.921557</td>\n      <td>0.200995</td>\n      <td>-2.346836</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2</td>\n      <td>54.415625</td>\n      <td>115.325207</td>\n      <td>86.279811</td>\n      <td>79.842617</td>\n      <td>41.354535</td>\n      <td>57.572824</td>\n      <td>29.798652</td>\n      <td>27.533800</td>\n      <td>12.925224</td>\n      <td>...</td>\n      <td>3.819550</td>\n      <td>2.731836</td>\n      <td>4.763795</td>\n      <td>1.898447</td>\n      <td>2.378209</td>\n      <td>2.500515</td>\n      <td>3.305095</td>\n      <td>2.035448</td>\n      <td>0.501000</td>\n      <td>0.920145</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2</td>\n      <td>1.027493</td>\n      <td>2.622392</td>\n      <td>8.170351</td>\n      <td>1.964630</td>\n      <td>5.602924</td>\n      <td>1.842355</td>\n      <td>5.649830</td>\n      <td>3.664765</td>\n      <td>3.457500</td>\n      <td>...</td>\n      <td>0.478062</td>\n      <td>0.182575</td>\n      <td>0.981841</td>\n      <td>0.268720</td>\n      <td>0.039398</td>\n      <td>0.081701</td>\n      <td>0.060758</td>\n      <td>0.125317</td>\n      <td>1.101009</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.200995</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>8307</th>\n      <td>0</td>\n      <td>58.509531</td>\n      <td>24.130297</td>\n      <td>77.456597</td>\n      <td>119.575308</td>\n      <td>21.386708</td>\n      <td>25.598958</td>\n      <td>61.105373</td>\n      <td>22.656495</td>\n      <td>24.167232</td>\n      <td>...</td>\n      <td>3.931479</td>\n      <td>1.968162</td>\n      <td>3.062893</td>\n      <td>1.562262</td>\n      <td>2.931484</td>\n      <td>2.914780</td>\n      <td>2.472442</td>\n      <td>4.033660</td>\n      <td>0.000992</td>\n      <td>2.001416</td>\n    </tr>\n    <tr>\n      <th>8308</th>\n      <td>0</td>\n      <td>18.844414</td>\n      <td>60.880904</td>\n      <td>42.080082</td>\n      <td>99.809994</td>\n      <td>60.119598</td>\n      <td>74.158525</td>\n      <td>45.799685</td>\n      <td>43.245535</td>\n      <td>37.006743</td>\n      <td>...</td>\n      <td>1.771997</td>\n      <td>2.485157</td>\n      <td>3.483579</td>\n      <td>3.607862</td>\n      <td>3.197097</td>\n      <td>2.469661</td>\n      <td>2.292118</td>\n      <td>2.642321</td>\n      <td>0.100994</td>\n      <td>0.160058</td>\n    </tr>\n    <tr>\n      <th>8309</th>\n      <td>0</td>\n      <td>55.335973</td>\n      <td>20.153225</td>\n      <td>46.843079</td>\n      <td>63.216221</td>\n      <td>57.758503</td>\n      <td>32.045904</td>\n      <td>27.292346</td>\n      <td>17.916218</td>\n      <td>16.484902</td>\n      <td>...</td>\n      <td>3.273334</td>\n      <td>2.513552</td>\n      <td>2.625054</td>\n      <td>1.996016</td>\n      <td>2.268182</td>\n      <td>3.123659</td>\n      <td>3.243166</td>\n      <td>4.084404</td>\n      <td>0.000992</td>\n      <td>1.970815</td>\n    </tr>\n    <tr>\n      <th>8310</th>\n      <td>0</td>\n      <td>28.903322</td>\n      <td>21.978773</td>\n      <td>34.023285</td>\n      <td>69.517689</td>\n      <td>42.079554</td>\n      <td>68.849285</td>\n      <td>72.357107</td>\n      <td>43.558518</td>\n      <td>33.260433</td>\n      <td>...</td>\n      <td>2.236040</td>\n      <td>2.790370</td>\n      <td>2.339984</td>\n      <td>2.798732</td>\n      <td>3.253075</td>\n      <td>6.331714</td>\n      <td>1.341946</td>\n      <td>2.979213</td>\n      <td>0.000992</td>\n      <td>0.134202</td>\n    </tr>\n    <tr>\n      <th>8311</th>\n      <td>0</td>\n      <td>20.463551</td>\n      <td>53.105440</td>\n      <td>25.725438</td>\n      <td>86.511128</td>\n      <td>42.522998</td>\n      <td>25.147855</td>\n      <td>58.176851</td>\n      <td>33.713236</td>\n      <td>45.624965</td>\n      <td>...</td>\n      <td>11.106229</td>\n      <td>8.483935</td>\n      <td>7.629401</td>\n      <td>8.949675</td>\n      <td>5.540413</td>\n      <td>15.168735</td>\n      <td>7.626594</td>\n      <td>6.021769</td>\n      <td>0.000992</td>\n      <td>0.787857</td>\n    </tr>\n  </tbody>\n</table>\n<p>12678 rows × 43 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "w/p\n",
    "for i in range(11):\n",
    "  df = pd.concat([df,ps])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Examples:\n    Total: 12678\n    P: 4404 (34.74% of total)\n    S: 3965 (31.27% of total)\n    W: 4309 (33.99% of total)\n\n"
     ]
    }
   ],
   "source": [
    "p,s,w = np.bincount(df['Class'])\n",
    "total = p + s + w\n",
    "print('Examples:\\n    Total: {}\\n    P: {} ({:.2f}% of total)\\n    S: {} ({:.2f}% of total)\\n    W: {} ({:.2f}% of total)\\n'.format(\n",
    "    total, p, 100 * p / total,s,100 * s / total,w,100 * w / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "df = pd.read_csv(\"data/control_preprocessed.csv\")\n",
    "\n",
    "# Use a utility from sklearn to split and shuffle our dataset.\n",
    "train_df, test_df = train_test_split(df, test_size=0.2)\n",
    "# train_df, val_df = train_test_split(train_df, test_size=0.2)\n",
    "\n",
    "# Form np arrays of labels and features.\n",
    "train_labels = np.array(train_df.pop('Class'))\n",
    "p_train_labels = train_labels == 0\n",
    "s_train_labels = train_labels == 1\n",
    "w_train_labels = train_labels == 2\n",
    "\n",
    "# val_labels = np.array(val_df.pop('Class'))\n",
    "test_labels = np.array(test_df.pop('Class'))\n",
    "\n",
    "train_features = np.array(train_df)\n",
    "# val_features = np.array(val_df)\n",
    "test_features = np.array(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "def get_compiled_model(n,dropout=True):\n",
    "    \"\"\"\n",
    "    Function to create model. This is a sequential model, meaning layers execute\n",
    "    one after the other. We have an input shape corresponding to the feature set,\n",
    "    one hidden layer with 10 neurons and a relu activation, then an output layer\n",
    "    with 3 neurons and a sigmoid activation function. We compute loss with\n",
    "    categorical crossentropy and optimize with adam, which I believe is something\n",
    "    about an adaptive learning rate. I do not know what the parameter from_logits\n",
    "    is about.\n",
    "    \"\"\"\n",
    "    if(dropout):\n",
    "        model = tf.keras.Sequential([\n",
    "        keras.layers.Dense(n, activation='relu',input_shape=(train_features.shape[-1],)),\n",
    "        keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(3, activation='sigmoid')\n",
    "        ])\n",
    "    else:\n",
    "        model = tf.keras.Sequential([\n",
    "        keras.layers.Dense(n, activation='relu',input_shape=(train_features.shape[-1],)),\n",
    "        tf.keras.layers.Dense(3, activation='sigmoid')\n",
    "        ])\n",
    "    model.compile(optimizer=keras.optimizers.Adam(lr=1e-3),\n",
    "                loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy'])\n",
    "    return model\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 200\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='accuracy', \n",
    "    verbose=1,\n",
    "    patience=100,\n",
    "    mode='max',\n",
    "    restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(hln):\n",
    "    model = get_compiled_model(hln,dropout=True)\n",
    "    \"\"\"\n",
    "    We one-hot encode the targets. Mathematically, this is good for calculating\n",
    "    loss. CategoricalCrossEntropy simplifies to a negative log when targets are\n",
    "    one-hot encoded. However, I simply recieved an error from model.fit when I \n",
    "    did not one-hot encode.\n",
    "      @y : targets\n",
    "      @depth : number of targets\n",
    "    \"\"\"\n",
    "    baseline_history = model.fit(\n",
    "        train_features,\n",
    "        tf.one_hot(train_labels,depth=3),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        epochs=EPOCHS,\n",
    "        callbacks=[early_stopping])\n",
    "    train_predictions_baseline = model.predict(train_features, batch_size=BATCH_SIZE)\n",
    "    test_predictions_baseline = model.predict(test_features, batch_size=BATCH_SIZE)\n",
    "    baseline_results = model.evaluate(test_features, tf.one_hot(test_labels,depth=3),\n",
    "                                      batch_size=BATCH_SIZE, verbose=0)\n",
    "    plot_cm(tf.one_hot(test_labels,depth=3).numpy().argmax(axis=1), test_predictions_baseline.argmax(axis=1),baseline_results,hln)\n",
    "    plt.savefig(str(hln),bbox_inches='tight')"
   ]
  }
 ]
}