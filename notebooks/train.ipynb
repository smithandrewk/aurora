{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from scripts.utils import *\n",
    "\n",
    "import pandas as pd \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import os.path\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from time import time\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "source": [
    "## execute make fd"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "## Preprocess\n",
    "for file in os.listdir(\"data/renamed\"):\n",
    "    preprocess(file)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING *** file size (6776223) not 512 + multiple of sector size (512)\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** file size (6905920) not 512 + multiple of sector size (512)\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "0-0.5\n",
      "WARNING *** file size (6905056) not 512 + multiple of sector size (512)\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "0-0.5\n",
      "WARNING *** file size (6904822) not 512 + multiple of sector size (512)\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "0-0.5\n",
      "WARNING *** file size (6781445) not 512 + multiple of sector size (512)\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** file size (6764031) not 512 + multiple of sector size (512)\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "0-0.5\n",
      "WARNING *** file size (6902554) not 512 + multiple of sector size (512)\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "0-0.5\n",
      "WARNING *** file size (6903122) not 512 + multiple of sector size (512)\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "0-0.5\n",
      "WARNING *** file size (6901222) not 512 + multiple of sector size (512)\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "0-0.5\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "0-0.5\n",
      "WARNING *** file size (6902050) not 512 + multiple of sector size (512)\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "0-0.5\n",
      "WARNING *** file size (6782131) not 512 + multiple of sector size (512)\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** file size (6903922) not 512 + multiple of sector size (512)\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "0-0.5\n",
      "WARNING *** file size (6903328) not 512 + multiple of sector size (512)\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "0-0.5\n",
      "WARNING *** file size (6768211) not 512 + multiple of sector size (512)\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** file size (6902680) not 512 + multiple of sector size (512)\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "0-0.5\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "0-0.5\n",
      "WARNING *** file size (6682211) not 512 + multiple of sector size (512)\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** file size (6907054) not 512 + multiple of sector size (512)\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "0-0.5\n",
      "WARNING *** file size (6884325) not 512 + multiple of sector size (512)\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "0-0.5\n",
      "WARNING *** file size (6902356) not 512 + multiple of sector size (512)\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "0-0.5\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import pandas as pd\n",
    "\n",
    "for file in os.listdir(\"data/preprocessed\"):\n",
    "    df = pd.read_csv(\"data/preprocessed/\"+file)\n",
    "    print(\"======================================\"+file)\n",
    "    if(df.columns[0]!=\"Class\"):\n",
    "        print(\"NOT SCORED\")\n",
    "        continue\n",
    "    if(df.columns[1]!=\"0-0.5\"):\n",
    "        df.rename(columns={\"EEG 1 (0-0.5 Hz, 0-0.5Hz , 10s) (Mean, 10s)\":\"0-0.5\"},inplace=True)\n",
    "    EEG_2 = df[\"EEG 2\"]\n",
    "    Activity = df[\"Activity\"]\n",
    "    X = df.iloc[:,:-2]\n",
    "    X.insert(X.shape[1],\"EEG 2\",EEG_2)\n",
    "    X.insert(X.shape[1],\"Activity\",Activity)\n",
    "    X.to_csv(\"data/preprocessed/\"+file,index=False)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "======================================23_preprocessed.csv\n",
      "NOT SCORED\n",
      "======================================5_preprocessed.csv\n",
      "======================================8_preprocessed.csv\n",
      "======================================4_preprocessed.csv\n",
      "======================================3_preprocessed.csv\n",
      "======================================2_preprocessed.csv\n",
      "======================================6_preprocessed.csv\n",
      "======================================20_preprocessed.csv\n",
      "======================================9_preprocessed.csv\n",
      "======================================10_preprocessed.csv\n",
      "======================================7_preprocessed.csv\n",
      "NOT SCORED\n",
      "======================================16_preprocessed.csv\n",
      "NOT SCORED\n",
      "======================================22_preprocessed.csv\n",
      "======================================1_preprocessed.csv\n",
      "NOT SCORED\n",
      "======================================21_preprocessed.csv\n",
      "NOT SCORED\n",
      "======================================13_preprocessed.csv\n",
      "======================================0_preprocessed.csv\n",
      "======================================11_preprocessed.csv\n",
      "NOT SCORED\n",
      "======================================19_preprocessed.csv\n",
      "======================================17_preprocessed.csv\n",
      "======================================15_preprocessed.csv\n",
      "======================================18_preprocessed.csv\n",
      "======================================14_preprocessed.csv\n",
      "======================================12_preprocessed.csv\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "## Concatenate\n",
    "import pandas as pd\n",
    "\n",
    "X = pd.DataFrame()\n",
    "\n",
    "for file in os.listdir(\"data/preprocessed\"):\n",
    "    df = pd.read_csv(\"data/preprocessed/\"+file)\n",
    "    if(df.columns[0]!=\"Class\"):\n",
    "        print(file+\"NOT SCORED\")\n",
    "        continue\n",
    "    X = pd.concat([X,df])\n",
    "\n",
    "X\n",
    "X.to_csv(\"data/X_preprocessed.csv\",index=False)\n",
    "p,s,w = class_count(X)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "23_preprocessed.csvNOT SCORED\n",
      "7_preprocessed.csvNOT SCORED\n",
      "16_preprocessed.csvNOT SCORED\n",
      "1_preprocessed.csvNOT SCORED\n",
      "21_preprocessed.csvNOT SCORED\n",
      "11_preprocessed.csvNOT SCORED\n",
      "Examples:\n",
      "    Total: 154043\n",
      "    P: 10007 (6.50% of total)\n",
      "    S: 64346 (41.77% of total)\n",
      "    W: 79690 (51.73% of total)\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "X"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      Class       0-0.5       0.5-1       1-1.5      1.5-2      2-2.5  \\\n",
       "0         2  112.466219  386.275243  111.214307  94.589533  65.982601   \n",
       "1         2  117.932295  124.743146   63.962187  41.514800  52.006847   \n",
       "2         2   47.730008   56.238974   69.913574  28.844014  49.602042   \n",
       "3         2  126.214757  263.413074   22.690480  62.291360  51.319366   \n",
       "4         2   65.565947   84.330071   44.160341  74.342147  47.547590   \n",
       "...     ...         ...         ...         ...        ...        ...   \n",
       "8635      2  176.536240  258.705957   59.153833  63.788601  37.547656   \n",
       "8636      2   96.872266  154.686539  142.372559  73.771304  32.954706   \n",
       "8637      2  208.590584  305.591292   81.630504  60.119215  43.539959   \n",
       "8638      2   85.126105   37.888519   64.269068  79.333006  45.920712   \n",
       "8639      2  161.303949  162.892117  105.825878  44.856001  59.587537   \n",
       "\n",
       "          2.5-3      3-3.5      3.5-4      4-4.5  ...   16-16.5   16.5-17  \\\n",
       "0     32.481262  23.512462  20.022571  42.155020  ...  3.614764  6.002455   \n",
       "1     37.215005  33.881616  30.515775  22.966995  ...  3.659783  8.841288   \n",
       "2     58.413987  15.268867  31.066717  29.390456  ...  4.259227  3.720859   \n",
       "3     45.151023  17.741685  18.009278  27.517800  ...  2.829078  4.075956   \n",
       "4     31.381113  49.441001  49.994171  31.835481  ...  2.837114  5.159813   \n",
       "...         ...        ...        ...        ...  ...       ...       ...   \n",
       "8635  14.483064  17.090895  11.095073   9.814588  ...  3.772814  2.483775   \n",
       "8636  15.150568  23.685892  36.340840  27.408102  ...  4.280660  2.865040   \n",
       "8637  34.755211  17.904623  16.940312   9.056965  ...  4.203222  3.564343   \n",
       "8638  55.105410  36.009151  18.523926  15.341147  ...  1.429998  2.991180   \n",
       "8639  11.993086  28.987104  26.577669  36.888473  ...  2.446932  2.338118   \n",
       "\n",
       "       17-17.5   17.5-18   18-18.5   18.5-19   19-19.5   19.5-20     EEG 2  \\\n",
       "0     5.614338  4.946812  1.958384  4.844751  2.486510  3.610257  2.206653   \n",
       "1     4.715294  9.071930  6.063815  6.109256  3.298252  4.919295 -1.473123   \n",
       "2     4.329251  5.244743  2.048360  8.237504  2.844319  1.607012  3.520474   \n",
       "3     3.950742  6.305151  1.602701  3.240890  2.262298  1.961984  0.121365   \n",
       "4     3.976099  3.185130  3.847092  3.473680  4.651700  4.070736 -5.180086   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "8635  2.847549  4.251519  1.869109  2.437425  0.950953  1.739877 -6.036284   \n",
       "8636  2.109152  4.876663  2.882300  2.904351  2.979001  1.525098 -2.057861   \n",
       "8637  0.949924  2.224930  2.787905  1.831310  3.607349  1.504794  5.535449   \n",
       "8638  2.694050  2.938516  3.912944  1.644818  1.285005  1.173186 -3.482297   \n",
       "8639  2.103130  1.239183  3.234110  2.169133  1.601895  1.436409  5.424898   \n",
       "\n",
       "      Activity  \n",
       "0     0.101093  \n",
       "1     0.200995  \n",
       "2     0.701697  \n",
       "3     0.500405  \n",
       "4     0.900907  \n",
       "...        ...  \n",
       "8635  0.201094  \n",
       "8636  0.100994  \n",
       "8637  0.501397  \n",
       "8638  0.601299  \n",
       "8639  0.100994  \n",
       "\n",
       "[154043 rows x 43 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>0-0.5</th>\n",
       "      <th>0.5-1</th>\n",
       "      <th>1-1.5</th>\n",
       "      <th>1.5-2</th>\n",
       "      <th>2-2.5</th>\n",
       "      <th>2.5-3</th>\n",
       "      <th>3-3.5</th>\n",
       "      <th>3.5-4</th>\n",
       "      <th>4-4.5</th>\n",
       "      <th>...</th>\n",
       "      <th>16-16.5</th>\n",
       "      <th>16.5-17</th>\n",
       "      <th>17-17.5</th>\n",
       "      <th>17.5-18</th>\n",
       "      <th>18-18.5</th>\n",
       "      <th>18.5-19</th>\n",
       "      <th>19-19.5</th>\n",
       "      <th>19.5-20</th>\n",
       "      <th>EEG 2</th>\n",
       "      <th>Activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>112.466219</td>\n",
       "      <td>386.275243</td>\n",
       "      <td>111.214307</td>\n",
       "      <td>94.589533</td>\n",
       "      <td>65.982601</td>\n",
       "      <td>32.481262</td>\n",
       "      <td>23.512462</td>\n",
       "      <td>20.022571</td>\n",
       "      <td>42.155020</td>\n",
       "      <td>...</td>\n",
       "      <td>3.614764</td>\n",
       "      <td>6.002455</td>\n",
       "      <td>5.614338</td>\n",
       "      <td>4.946812</td>\n",
       "      <td>1.958384</td>\n",
       "      <td>4.844751</td>\n",
       "      <td>2.486510</td>\n",
       "      <td>3.610257</td>\n",
       "      <td>2.206653</td>\n",
       "      <td>0.101093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>117.932295</td>\n",
       "      <td>124.743146</td>\n",
       "      <td>63.962187</td>\n",
       "      <td>41.514800</td>\n",
       "      <td>52.006847</td>\n",
       "      <td>37.215005</td>\n",
       "      <td>33.881616</td>\n",
       "      <td>30.515775</td>\n",
       "      <td>22.966995</td>\n",
       "      <td>...</td>\n",
       "      <td>3.659783</td>\n",
       "      <td>8.841288</td>\n",
       "      <td>4.715294</td>\n",
       "      <td>9.071930</td>\n",
       "      <td>6.063815</td>\n",
       "      <td>6.109256</td>\n",
       "      <td>3.298252</td>\n",
       "      <td>4.919295</td>\n",
       "      <td>-1.473123</td>\n",
       "      <td>0.200995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>47.730008</td>\n",
       "      <td>56.238974</td>\n",
       "      <td>69.913574</td>\n",
       "      <td>28.844014</td>\n",
       "      <td>49.602042</td>\n",
       "      <td>58.413987</td>\n",
       "      <td>15.268867</td>\n",
       "      <td>31.066717</td>\n",
       "      <td>29.390456</td>\n",
       "      <td>...</td>\n",
       "      <td>4.259227</td>\n",
       "      <td>3.720859</td>\n",
       "      <td>4.329251</td>\n",
       "      <td>5.244743</td>\n",
       "      <td>2.048360</td>\n",
       "      <td>8.237504</td>\n",
       "      <td>2.844319</td>\n",
       "      <td>1.607012</td>\n",
       "      <td>3.520474</td>\n",
       "      <td>0.701697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>126.214757</td>\n",
       "      <td>263.413074</td>\n",
       "      <td>22.690480</td>\n",
       "      <td>62.291360</td>\n",
       "      <td>51.319366</td>\n",
       "      <td>45.151023</td>\n",
       "      <td>17.741685</td>\n",
       "      <td>18.009278</td>\n",
       "      <td>27.517800</td>\n",
       "      <td>...</td>\n",
       "      <td>2.829078</td>\n",
       "      <td>4.075956</td>\n",
       "      <td>3.950742</td>\n",
       "      <td>6.305151</td>\n",
       "      <td>1.602701</td>\n",
       "      <td>3.240890</td>\n",
       "      <td>2.262298</td>\n",
       "      <td>1.961984</td>\n",
       "      <td>0.121365</td>\n",
       "      <td>0.500405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>65.565947</td>\n",
       "      <td>84.330071</td>\n",
       "      <td>44.160341</td>\n",
       "      <td>74.342147</td>\n",
       "      <td>47.547590</td>\n",
       "      <td>31.381113</td>\n",
       "      <td>49.441001</td>\n",
       "      <td>49.994171</td>\n",
       "      <td>31.835481</td>\n",
       "      <td>...</td>\n",
       "      <td>2.837114</td>\n",
       "      <td>5.159813</td>\n",
       "      <td>3.976099</td>\n",
       "      <td>3.185130</td>\n",
       "      <td>3.847092</td>\n",
       "      <td>3.473680</td>\n",
       "      <td>4.651700</td>\n",
       "      <td>4.070736</td>\n",
       "      <td>-5.180086</td>\n",
       "      <td>0.900907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8635</th>\n",
       "      <td>2</td>\n",
       "      <td>176.536240</td>\n",
       "      <td>258.705957</td>\n",
       "      <td>59.153833</td>\n",
       "      <td>63.788601</td>\n",
       "      <td>37.547656</td>\n",
       "      <td>14.483064</td>\n",
       "      <td>17.090895</td>\n",
       "      <td>11.095073</td>\n",
       "      <td>9.814588</td>\n",
       "      <td>...</td>\n",
       "      <td>3.772814</td>\n",
       "      <td>2.483775</td>\n",
       "      <td>2.847549</td>\n",
       "      <td>4.251519</td>\n",
       "      <td>1.869109</td>\n",
       "      <td>2.437425</td>\n",
       "      <td>0.950953</td>\n",
       "      <td>1.739877</td>\n",
       "      <td>-6.036284</td>\n",
       "      <td>0.201094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8636</th>\n",
       "      <td>2</td>\n",
       "      <td>96.872266</td>\n",
       "      <td>154.686539</td>\n",
       "      <td>142.372559</td>\n",
       "      <td>73.771304</td>\n",
       "      <td>32.954706</td>\n",
       "      <td>15.150568</td>\n",
       "      <td>23.685892</td>\n",
       "      <td>36.340840</td>\n",
       "      <td>27.408102</td>\n",
       "      <td>...</td>\n",
       "      <td>4.280660</td>\n",
       "      <td>2.865040</td>\n",
       "      <td>2.109152</td>\n",
       "      <td>4.876663</td>\n",
       "      <td>2.882300</td>\n",
       "      <td>2.904351</td>\n",
       "      <td>2.979001</td>\n",
       "      <td>1.525098</td>\n",
       "      <td>-2.057861</td>\n",
       "      <td>0.100994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8637</th>\n",
       "      <td>2</td>\n",
       "      <td>208.590584</td>\n",
       "      <td>305.591292</td>\n",
       "      <td>81.630504</td>\n",
       "      <td>60.119215</td>\n",
       "      <td>43.539959</td>\n",
       "      <td>34.755211</td>\n",
       "      <td>17.904623</td>\n",
       "      <td>16.940312</td>\n",
       "      <td>9.056965</td>\n",
       "      <td>...</td>\n",
       "      <td>4.203222</td>\n",
       "      <td>3.564343</td>\n",
       "      <td>0.949924</td>\n",
       "      <td>2.224930</td>\n",
       "      <td>2.787905</td>\n",
       "      <td>1.831310</td>\n",
       "      <td>3.607349</td>\n",
       "      <td>1.504794</td>\n",
       "      <td>5.535449</td>\n",
       "      <td>0.501397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8638</th>\n",
       "      <td>2</td>\n",
       "      <td>85.126105</td>\n",
       "      <td>37.888519</td>\n",
       "      <td>64.269068</td>\n",
       "      <td>79.333006</td>\n",
       "      <td>45.920712</td>\n",
       "      <td>55.105410</td>\n",
       "      <td>36.009151</td>\n",
       "      <td>18.523926</td>\n",
       "      <td>15.341147</td>\n",
       "      <td>...</td>\n",
       "      <td>1.429998</td>\n",
       "      <td>2.991180</td>\n",
       "      <td>2.694050</td>\n",
       "      <td>2.938516</td>\n",
       "      <td>3.912944</td>\n",
       "      <td>1.644818</td>\n",
       "      <td>1.285005</td>\n",
       "      <td>1.173186</td>\n",
       "      <td>-3.482297</td>\n",
       "      <td>0.601299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8639</th>\n",
       "      <td>2</td>\n",
       "      <td>161.303949</td>\n",
       "      <td>162.892117</td>\n",
       "      <td>105.825878</td>\n",
       "      <td>44.856001</td>\n",
       "      <td>59.587537</td>\n",
       "      <td>11.993086</td>\n",
       "      <td>28.987104</td>\n",
       "      <td>26.577669</td>\n",
       "      <td>36.888473</td>\n",
       "      <td>...</td>\n",
       "      <td>2.446932</td>\n",
       "      <td>2.338118</td>\n",
       "      <td>2.103130</td>\n",
       "      <td>1.239183</td>\n",
       "      <td>3.234110</td>\n",
       "      <td>2.169133</td>\n",
       "      <td>1.601895</td>\n",
       "      <td>1.436409</td>\n",
       "      <td>5.424898</td>\n",
       "      <td>0.100994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>154043 rows Ã— 43 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "target_filename = 'X' # or 'control' or 'deprivation'\n",
    "df = pd.read_csv(\"data/\"+target_filename+\"_preprocessed.csv\")\n",
    "df\n",
    "# Balancing\n",
    "ps = df.loc[df[\"Class\"]==0]\n",
    "ss = df.loc[df[\"Class\"]==1]\n",
    "ws = df.loc[df[\"Class\"]==2]\n",
    "for i in range(int(w/p)):\n",
    "  df = pd.concat([df,ps])\n",
    "p,s,w = class_count(df)\n",
    "\n",
    "df.to_csv(\"data/\"+target_filename+\"_balanced.csv\",index=False)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Examples:\n",
      "    Total: 224092\n",
      "    P: 80056 (35.72% of total)\n",
      "    S: 64346 (28.71% of total)\n",
      "    W: 79690 (35.56% of total)\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "df = pd.read_csv(\"data/\"+target_filename+\"_balanced.csv\")\n",
    "target_filename = 'X' # or 'control' or 'deprivation'\n",
    "\n",
    "# df = pd.read_csv(\"data/\"+target_filename+\"_preprocessed.csv\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Use a utility from sklearn to split and shuffle our dataset.\n",
    "train_df, test_df = train_test_split(df, test_size=0.2)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.2)\n",
    "\n",
    "# Form np arrays of labels and features.\n",
    "train_labels = np.array(train_df.pop('Class'))\n",
    "val_labels = np.array(val_df.pop('Class'))\n",
    "test_labels = np.array(test_df.pop('Class'))\n",
    "print(train_labels.shape)\n",
    "print(val_labels.shape)\n",
    "print(test_labels.shape)\n",
    "\n",
    "\n",
    "train_features = np.array(train_df)\n",
    "val_features = np.array(val_df)\n",
    "test_features = np.array(test_df)\n",
    "\n",
    "total = p + s + w\n",
    "# Scaling by total/2 helps keep the loss to a similar magnitude.\n",
    "# The sum of the weights of all examples stays the same.\n",
    "weight_for_p = (1 / p)*(total)/2.0 \n",
    "weight_for_w = (1 / w)*(total)/2.0\n",
    "weight_for_s = (1 / s)*(total)/2.0\n",
    "\n",
    "\n",
    "class_weight = {0: weight_for_p, 1: weight_for_s, 2: weight_for_w}\n",
    "\n",
    "print('Weight for class 0: {:.2f}'.format(weight_for_p))\n",
    "print('Weight for class 1: {:.2f}'.format(weight_for_s))\n",
    "print('Weight for class 2: {:.2f}'.format(weight_for_w))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(143418,)\n",
      "(35855,)\n",
      "(44819,)\n",
      "Weight for class 0: 1.40\n",
      "Weight for class 1: 1.74\n",
      "Weight for class 2: 1.41\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "train_history,test_history,date,model = train(INPUT_FEATURES=(train_features.shape[-1],),\n",
    "                                   hln=200,\n",
    "                                   EPOCHS=100,\n",
    "                                   weights=True)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/andrew/.local/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py:355: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n",
      "/home/andrew/.local/lib/python3.8/site-packages/keras/backend.py:4846: UserWarning: \"`categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/100\n",
      "718/718 [==============================] - 3s 3ms/step - loss: 21.9806 - categorical_accuracy: 0.6431 - precision: 0.4356 - recall: 0.6491 - auc: 0.6537 - val_loss: 3.0812 - val_categorical_accuracy: 0.7670 - val_precision: 0.4781 - val_recall: 0.5836 - val_auc: 0.6816\n",
      "Epoch 2/100\n",
      "718/718 [==============================] - 2s 2ms/step - loss: 7.7459 - categorical_accuracy: 0.7447 - precision: 0.4163 - recall: 0.6254 - auc: 0.6192 - val_loss: 2.4214 - val_categorical_accuracy: 0.8180 - val_precision: 0.4828 - val_recall: 0.6933 - val_auc: 0.6989\n",
      "Epoch 3/100\n",
      "718/718 [==============================] - 1s 2ms/step - loss: 4.6674 - categorical_accuracy: 0.7688 - precision: 0.4146 - recall: 0.6870 - auc: 0.6283 - val_loss: 2.8077 - val_categorical_accuracy: 0.8198 - val_precision: 0.4641 - val_recall: 0.8264 - val_auc: 0.7345\n",
      "Epoch 4/100\n",
      "718/718 [==============================] - 2s 2ms/step - loss: 2.7416 - categorical_accuracy: 0.7843 - precision: 0.4415 - recall: 0.5918 - auc: 0.6330 - val_loss: 0.9826 - val_categorical_accuracy: 0.8254 - val_precision: 0.5178 - val_recall: 0.6302 - val_auc: 0.7194\n",
      "Epoch 5/100\n",
      "718/718 [==============================] - 2s 2ms/step - loss: 1.7502 - categorical_accuracy: 0.7885 - precision: 0.4272 - recall: 0.6650 - auc: 0.6374 - val_loss: 0.9944 - val_categorical_accuracy: 0.8253 - val_precision: 0.4574 - val_recall: 0.9060 - val_auc: 0.7765\n",
      "Epoch 6/100\n",
      "718/718 [==============================] - 2s 2ms/step - loss: 1.3097 - categorical_accuracy: 0.7695 - precision: 0.3942 - recall: 0.8445 - auc: 0.6415 - val_loss: 0.5683 - val_categorical_accuracy: 0.8204 - val_precision: 0.3954 - val_recall: 0.9713 - val_auc: 0.6897\n",
      "Epoch 7/100\n",
      "718/718 [==============================] - 2s 2ms/step - loss: 0.8934 - categorical_accuracy: 0.7580 - precision: 0.3898 - recall: 0.8717 - auc: 0.6365 - val_loss: 0.4842 - val_categorical_accuracy: 0.8181 - val_precision: 0.3891 - val_recall: 0.9739 - val_auc: 0.6925\n",
      "Epoch 8/100\n",
      "718/718 [==============================] - 1s 2ms/step - loss: 0.7938 - categorical_accuracy: 0.7525 - precision: 0.3884 - recall: 0.8773 - auc: 0.6343 - val_loss: 0.4530 - val_categorical_accuracy: 0.8127 - val_precision: 0.4133 - val_recall: 0.9537 - val_auc: 0.6810\n",
      "Epoch 9/100\n",
      "718/718 [==============================] - 2s 2ms/step - loss: 0.8009 - categorical_accuracy: 0.7592 - precision: 0.3998 - recall: 0.8448 - auc: 0.6392 - val_loss: 0.4427 - val_categorical_accuracy: 0.8154 - val_precision: 0.4109 - val_recall: 0.9705 - val_auc: 0.6918\n",
      "Epoch 10/100\n",
      "718/718 [==============================] - 2s 2ms/step - loss: 0.7661 - categorical_accuracy: 0.7643 - precision: 0.4017 - recall: 0.8407 - auc: 0.6415 - val_loss: 0.4986 - val_categorical_accuracy: 0.8167 - val_precision: 0.4159 - val_recall: 0.9244 - val_auc: 0.6697\n",
      "Epoch 11/100\n",
      "718/718 [==============================] - 2s 2ms/step - loss: 0.7641 - categorical_accuracy: 0.7884 - precision: 0.4243 - recall: 0.7200 - auc: 0.6414 - val_loss: 0.4479 - val_categorical_accuracy: 0.8505 - val_precision: 0.6207 - val_recall: 0.7004 - val_auc: 0.7887\n",
      "Epoch 12/100\n",
      "718/718 [==============================] - 2s 2ms/step - loss: 0.7510 - categorical_accuracy: 0.8033 - precision: 0.4423 - recall: 0.7029 - auc: 0.6581 - val_loss: 0.4354 - val_categorical_accuracy: 0.8491 - val_precision: 0.5740 - val_recall: 0.6816 - val_auc: 0.7681\n",
      "Epoch 13/100\n",
      "718/718 [==============================] - 1s 2ms/step - loss: 0.7717 - categorical_accuracy: 0.8072 - precision: 0.4481 - recall: 0.7009 - auc: 0.6654 - val_loss: 0.4372 - val_categorical_accuracy: 0.8454 - val_precision: 0.4777 - val_recall: 0.8693 - val_auc: 0.7722\n",
      "Epoch 14/100\n",
      "718/718 [==============================] - 2s 2ms/step - loss: 0.7508 - categorical_accuracy: 0.8011 - precision: 0.4365 - recall: 0.7870 - auc: 0.6754 - val_loss: 0.4260 - val_categorical_accuracy: 0.8519 - val_precision: 0.4817 - val_recall: 0.8904 - val_auc: 0.7749\n",
      "Epoch 15/100\n",
      "718/718 [==============================] - 2s 2ms/step - loss: 0.7358 - categorical_accuracy: 0.7978 - precision: 0.4335 - recall: 0.8080 - auc: 0.6788 - val_loss: 0.4230 - val_categorical_accuracy: 0.8537 - val_precision: 0.4638 - val_recall: 0.9430 - val_auc: 0.7715\n",
      "Epoch 16/100\n",
      "718/718 [==============================] - 2s 2ms/step - loss: 0.7290 - categorical_accuracy: 0.8037 - precision: 0.4426 - recall: 0.8156 - auc: 0.6928 - val_loss: 0.4216 - val_categorical_accuracy: 0.8522 - val_precision: 0.4895 - val_recall: 0.9333 - val_auc: 0.8196\n",
      "Epoch 17/100\n",
      "718/718 [==============================] - 2s 2ms/step - loss: 0.7310 - categorical_accuracy: 0.8179 - precision: 0.4717 - recall: 0.7553 - auc: 0.7057 - val_loss: 0.4842 - val_categorical_accuracy: 0.8512 - val_precision: 0.6125 - val_recall: 0.8427 - val_auc: 0.8586\n",
      "Epoch 18/100\n",
      "718/718 [==============================] - 1s 2ms/step - loss: 0.7151 - categorical_accuracy: 0.8234 - precision: 0.4870 - recall: 0.7277 - auc: 0.7118 - val_loss: 0.4100 - val_categorical_accuracy: 0.8571 - val_precision: 0.6200 - val_recall: 0.8308 - val_auc: 0.8647\n",
      "Epoch 19/100\n",
      "718/718 [==============================] - 2s 2ms/step - loss: 0.7149 - categorical_accuracy: 0.8225 - precision: 0.4911 - recall: 0.7361 - auc: 0.7163 - val_loss: 0.4205 - val_categorical_accuracy: 0.8539 - val_precision: 0.6158 - val_recall: 0.8784 - val_auc: 0.8876\n",
      "Epoch 20/100\n",
      "718/718 [==============================] - 2s 2ms/step - loss: 0.7217 - categorical_accuracy: 0.8239 - precision: 0.4912 - recall: 0.7551 - auc: 0.7237 - val_loss: 0.4200 - val_categorical_accuracy: 0.8588 - val_precision: 0.6420 - val_recall: 0.8737 - val_auc: 0.8935\n",
      "Epoch 21/100\n",
      "718/718 [==============================] - 2s 2ms/step - loss: 0.7082 - categorical_accuracy: 0.8240 - precision: 0.4928 - recall: 0.7565 - auc: 0.7260 - val_loss: 0.4104 - val_categorical_accuracy: 0.8589 - val_precision: 0.5020 - val_recall: 0.9586 - val_auc: 0.8663\n",
      "Epoch 22/100\n",
      "718/718 [==============================] - 2s 2ms/step - loss: 0.7016 - categorical_accuracy: 0.8205 - precision: 0.4706 - recall: 0.8291 - auc: 0.7305 - val_loss: 0.4168 - val_categorical_accuracy: 0.8566 - val_precision: 0.5557 - val_recall: 0.9371 - val_auc: 0.8850\n",
      "Epoch 23/100\n",
      "718/718 [==============================] - 1s 2ms/step - loss: 0.7019 - categorical_accuracy: 0.8213 - precision: 0.4755 - recall: 0.8328 - auc: 0.7353 - val_loss: 0.4039 - val_categorical_accuracy: 0.8580 - val_precision: 0.5024 - val_recall: 0.9526 - val_auc: 0.8619\n",
      "Epoch 24/100\n",
      "718/718 [==============================] - 2s 2ms/step - loss: 0.6999 - categorical_accuracy: 0.8242 - precision: 0.4774 - recall: 0.8279 - auc: 0.7380 - val_loss: 0.4104 - val_categorical_accuracy: 0.8531 - val_precision: 0.5080 - val_recall: 0.9456 - val_auc: 0.8587\n",
      "Epoch 25/100\n",
      "718/718 [==============================] - 2s 2ms/step - loss: 0.6959 - categorical_accuracy: 0.8283 - precision: 0.4883 - recall: 0.8173 - auc: 0.7447 - val_loss: 0.4085 - val_categorical_accuracy: 0.8576 - val_precision: 0.5852 - val_recall: 0.9397 - val_auc: 0.9094\n",
      "Epoch 26/100\n",
      "718/718 [==============================] - 2s 2ms/step - loss: 0.6999 - categorical_accuracy: 0.8325 - precision: 0.5011 - recall: 0.8058 - auc: 0.7570 - val_loss: 0.4017 - val_categorical_accuracy: 0.8592 - val_precision: 0.5485 - val_recall: 0.9517 - val_auc: 0.9036\n",
      "Epoch 27/100\n",
      "718/718 [==============================] - 2s 2ms/step - loss: 0.6954 - categorical_accuracy: 0.8325 - precision: 0.4953 - recall: 0.7965 - auc: 0.7515 - val_loss: 0.4004 - val_categorical_accuracy: 0.8592 - val_precision: 0.6122 - val_recall: 0.8864 - val_auc: 0.8917\n",
      "Epoch 28/100\n",
      "718/718 [==============================] - 1s 2ms/step - loss: 0.6902 - categorical_accuracy: 0.8324 - precision: 0.4940 - recall: 0.8055 - auc: 0.7517 - val_loss: 0.4048 - val_categorical_accuracy: 0.8586 - val_precision: 0.5216 - val_recall: 0.9505 - val_auc: 0.8868\n",
      "Epoch 29/100\n",
      "718/718 [==============================] - 2s 2ms/step - loss: 0.6902 - categorical_accuracy: 0.8307 - precision: 0.4859 - recall: 0.8390 - auc: 0.7527 - val_loss: 0.4143 - val_categorical_accuracy: 0.8583 - val_precision: 0.5381 - val_recall: 0.9454 - val_auc: 0.8827\n",
      "Epoch 30/100\n",
      "718/718 [==============================] - 2s 2ms/step - loss: 0.6899 - categorical_accuracy: 0.8288 - precision: 0.4836 - recall: 0.8387 - auc: 0.7512 - val_loss: 0.4034 - val_categorical_accuracy: 0.8585 - val_precision: 0.5185 - val_recall: 0.9357 - val_auc: 0.8797\n",
      "Epoch 31/100\n",
      "718/718 [==============================] - 2s 2ms/step - loss: 0.6859 - categorical_accuracy: 0.8302 - precision: 0.4829 - recall: 0.8464 - auc: 0.7506 - val_loss: 0.4100 - val_categorical_accuracy: 0.8502 - val_precision: 0.5504 - val_recall: 0.9344 - val_auc: 0.8769\n",
      "Epoch 32/100\n",
      "718/718 [==============================] - 2s 2ms/step - loss: 0.6871 - categorical_accuracy: 0.8274 - precision: 0.4780 - recall: 0.8485 - auc: 0.7476 - val_loss: 0.4002 - val_categorical_accuracy: 0.8588 - val_precision: 0.5382 - val_recall: 0.9307 - val_auc: 0.8902\n",
      "Epoch 33/100\n",
      "718/718 [==============================] - 1s 2ms/step - loss: 0.6931 - categorical_accuracy: 0.8360 - precision: 0.5192 - recall: 0.7858 - auc: 0.7662 - val_loss: 0.3980 - val_categorical_accuracy: 0.8573 - val_precision: 0.5715 - val_recall: 0.9249 - val_auc: 0.8969\n",
      "Epoch 34/100\n",
      "718/718 [==============================] - 2s 2ms/step - loss: 0.6893 - categorical_accuracy: 0.8369 - precision: 0.5008 - recall: 0.8064 - auc: 0.7625 - val_loss: 0.4112 - val_categorical_accuracy: 0.8562 - val_precision: 0.6680 - val_recall: 0.9119 - val_auc: 0.9215\n",
      "Epoch 35/100\n",
      "718/718 [==============================] - 2s 2ms/step - loss: 0.6913 - categorical_accuracy: 0.8370 - precision: 0.5519 - recall: 0.7661 - auc: 0.7794 - val_loss: 0.4046 - val_categorical_accuracy: 0.8547 - val_precision: 0.6633 - val_recall: 0.8797 - val_auc: 0.8978\n",
      "Epoch 36/100\n",
      "718/718 [==============================] - 2s 2ms/step - loss: 0.6830 - categorical_accuracy: 0.8397 - precision: 0.5554 - recall: 0.7598 - auc: 0.7771 - val_loss: 0.4425 - val_categorical_accuracy: 0.8608 - val_precision: 0.7232 - val_recall: 0.8729 - val_auc: 0.9175\n",
      "Epoch 37/100\n",
      "718/718 [==============================] - 2s 2ms/step - loss: 0.6932 - categorical_accuracy: 0.8378 - precision: 0.5474 - recall: 0.7673 - auc: 0.7765 - val_loss: 0.3970 - val_categorical_accuracy: 0.8597 - val_precision: 0.6300 - val_recall: 0.9117 - val_auc: 0.9019\n",
      "Epoch 38/100\n",
      "718/718 [==============================] - 1s 2ms/step - loss: 0.7013 - categorical_accuracy: 0.8349 - precision: 0.5340 - recall: 0.8019 - auc: 0.7812 - val_loss: 0.4140 - val_categorical_accuracy: 0.8573 - val_precision: 0.7045 - val_recall: 0.8846 - val_auc: 0.9215\n",
      "Epoch 39/100\n",
      "718/718 [==============================] - 2s 2ms/step - loss: 0.6895 - categorical_accuracy: 0.8347 - precision: 0.4945 - recall: 0.8480 - auc: 0.7715 - val_loss: 0.4085 - val_categorical_accuracy: 0.8585 - val_precision: 0.5611 - val_recall: 0.9239 - val_auc: 0.8774\n",
      "Epoch 40/100\n",
      "718/718 [==============================] - 2s 2ms/step - loss: 0.6887 - categorical_accuracy: 0.8355 - precision: 0.4875 - recall: 0.8210 - auc: 0.7548 - val_loss: 0.4040 - val_categorical_accuracy: 0.8609 - val_precision: 0.5866 - val_recall: 0.8886 - val_auc: 0.8831\n",
      "Epoch 41/100\n",
      "718/718 [==============================] - 2s 2ms/step - loss: 0.6784 - categorical_accuracy: 0.8355 - precision: 0.4840 - recall: 0.8302 - auc: 0.7568 - val_loss: 0.4023 - val_categorical_accuracy: 0.8566 - val_precision: 0.5277 - val_recall: 0.9430 - val_auc: 0.8917\n",
      "Epoch 42/100\n",
      "718/718 [==============================] - 2s 2ms/step - loss: 0.6795 - categorical_accuracy: 0.8382 - precision: 0.4906 - recall: 0.8238 - auc: 0.7613 - val_loss: 0.4050 - val_categorical_accuracy: 0.8612 - val_precision: 0.6133 - val_recall: 0.8879 - val_auc: 0.8934\n",
      "Epoch 43/100\n",
      "718/718 [==============================] - 1s 2ms/step - loss: 0.6896 - categorical_accuracy: 0.8393 - precision: 0.4962 - recall: 0.8022 - auc: 0.7562 - val_loss: 0.4155 - val_categorical_accuracy: 0.8551 - val_precision: 0.5659 - val_recall: 0.9182 - val_auc: 0.8950\n",
      "Epoch 44/100\n",
      "718/718 [==============================] - 2s 2ms/step - loss: 0.6775 - categorical_accuracy: 0.8365 - precision: 0.4737 - recall: 0.8599 - auc: 0.7598 - val_loss: 0.3987 - val_categorical_accuracy: 0.8595 - val_precision: 0.4998 - val_recall: 0.9408 - val_auc: 0.8677\n",
      "Epoch 45/100\n",
      "718/718 [==============================] - 2s 2ms/step - loss: 0.6757 - categorical_accuracy: 0.8369 - precision: 0.4745 - recall: 0.8515 - auc: 0.7591 - val_loss: 0.3987 - val_categorical_accuracy: 0.8579 - val_precision: 0.5244 - val_recall: 0.9234 - val_auc: 0.8739\n",
      "Epoch 46/100\n",
      "718/718 [==============================] - 2s 2ms/step - loss: 0.6775 - categorical_accuracy: 0.8385 - precision: 0.4857 - recall: 0.8385 - auc: 0.7633 - val_loss: 0.4037 - val_categorical_accuracy: 0.8583 - val_precision: 0.5700 - val_recall: 0.9059 - val_auc: 0.8782\n",
      "Epoch 47/100\n",
      "718/718 [==============================] - 2s 2ms/step - loss: 0.6793 - categorical_accuracy: 0.8368 - precision: 0.4828 - recall: 0.8408 - auc: 0.7613 - val_loss: 0.3968 - val_categorical_accuracy: 0.8580 - val_precision: 0.6024 - val_recall: 0.9156 - val_auc: 0.9078\n",
      "Epoch 48/100\n",
      "718/718 [==============================] - 1s 2ms/step - loss: 0.6975 - categorical_accuracy: 0.8408 - precision: 0.5389 - recall: 0.7512 - auc: 0.7668 - val_loss: 0.4010 - val_categorical_accuracy: 0.8570 - val_precision: 0.6986 - val_recall: 0.8763 - val_auc: 0.9203\n",
      "Epoch 49/100\n",
      "718/718 [==============================] - 2s 2ms/step - loss: 0.6786 - categorical_accuracy: 0.8412 - precision: 0.5487 - recall: 0.7553 - auc: 0.7733 - val_loss: 0.4017 - val_categorical_accuracy: 0.8578 - val_precision: 0.6493 - val_recall: 0.8863 - val_auc: 0.9038\n",
      "Epoch 50/100\n",
      "718/718 [==============================] - 2s 2ms/step - loss: 0.6866 - categorical_accuracy: 0.8403 - precision: 0.5363 - recall: 0.7617 - auc: 0.7665 - val_loss: 0.4010 - val_categorical_accuracy: 0.8560 - val_precision: 0.7139 - val_recall: 0.8148 - val_auc: 0.8987\n",
      "Epoch 51/100\n",
      "718/718 [==============================] - 2s 2ms/step - loss: 0.6717 - categorical_accuracy: 0.8412 - precision: 0.5568 - recall: 0.7262 - auc: 0.7669 - val_loss: 0.3987 - val_categorical_accuracy: 0.8607 - val_precision: 0.6404 - val_recall: 0.8612 - val_auc: 0.8939\n",
      "Epoch 52/100\n",
      "718/718 [==============================] - 2s 2ms/step - loss: 0.6665 - categorical_accuracy: 0.8453 - precision: 0.5526 - recall: 0.7478 - auc: 0.7758 - val_loss: 0.3982 - val_categorical_accuracy: 0.8580 - val_precision: 0.6598 - val_recall: 0.8790 - val_auc: 0.9094\n",
      "Epoch 53/100\n",
      "718/718 [==============================] - 1s 2ms/step - loss: 0.6643 - categorical_accuracy: 0.8439 - precision: 0.5295 - recall: 0.7670 - auc: 0.7699 - val_loss: 0.3937 - val_categorical_accuracy: 0.8614 - val_precision: 0.6593 - val_recall: 0.8508 - val_auc: 0.8968\n",
      "Epoch 54/100\n",
      "718/718 [==============================] - 2s 2ms/step - loss: 0.6739 - categorical_accuracy: 0.8424 - precision: 0.5264 - recall: 0.7787 - auc: 0.7702 - val_loss: 0.3948 - val_categorical_accuracy: 0.8633 - val_precision: 0.6217 - val_recall: 0.8627 - val_auc: 0.8760\n",
      "Epoch 55/100\n",
      "718/718 [==============================] - 2s 2ms/step - loss: 0.6697 - categorical_accuracy: 0.8443 - precision: 0.5156 - recall: 0.7702 - auc: 0.7577 - val_loss: 0.3971 - val_categorical_accuracy: 0.8633 - val_precision: 0.6295 - val_recall: 0.7944 - val_auc: 0.8607\n",
      "Epoch 56/100\n",
      "718/718 [==============================] - 2s 2ms/step - loss: 0.6691 - categorical_accuracy: 0.8434 - precision: 0.5105 - recall: 0.7879 - auc: 0.7638 - val_loss: 0.3990 - val_categorical_accuracy: 0.8602 - val_precision: 0.6982 - val_recall: 0.8453 - val_auc: 0.9065\n",
      "Epoch 57/100\n",
      "718/718 [==============================] - 2s 2ms/step - loss: 0.6680 - categorical_accuracy: 0.8422 - precision: 0.5119 - recall: 0.7841 - auc: 0.7639 - val_loss: 0.4087 - val_categorical_accuracy: 0.8489 - val_precision: 0.6184 - val_recall: 0.8561 - val_auc: 0.8791\n",
      "Epoch 58/100\n",
      "718/718 [==============================] - 1s 2ms/step - loss: 0.6662 - categorical_accuracy: 0.8428 - precision: 0.4931 - recall: 0.7952 - auc: 0.7555 - val_loss: 0.3921 - val_categorical_accuracy: 0.8629 - val_precision: 0.5937 - val_recall: 0.9253 - val_auc: 0.9032\n",
      "Epoch 59/100\n",
      "718/718 [==============================] - 2s 2ms/step - loss: 0.6739 - categorical_accuracy: 0.8412 - precision: 0.4929 - recall: 0.7925 - auc: 0.7540 - val_loss: 0.3943 - val_categorical_accuracy: 0.8618 - val_precision: 0.6067 - val_recall: 0.8703 - val_auc: 0.8891\n",
      "Epoch 60/100\n",
      "718/718 [==============================] - 2s 2ms/step - loss: 0.6804 - categorical_accuracy: 0.8425 - precision: 0.4955 - recall: 0.7881 - auc: 0.7550 - val_loss: 0.3988 - val_categorical_accuracy: 0.8602 - val_precision: 0.6867 - val_recall: 0.8346 - val_auc: 0.8989\n",
      "Epoch 61/100\n",
      "718/718 [==============================] - 2s 2ms/step - loss: 0.6842 - categorical_accuracy: 0.8416 - precision: 0.4973 - recall: 0.7902 - auc: 0.7551 - val_loss: 0.3922 - val_categorical_accuracy: 0.8610 - val_precision: 0.5286 - val_recall: 0.9372 - val_auc: 0.8934\n",
      "Epoch 62/100\n",
      "718/718 [==============================] - 2s 2ms/step - loss: 0.6725 - categorical_accuracy: 0.8412 - precision: 0.4863 - recall: 0.8177 - auc: 0.7556 - val_loss: 0.3986 - val_categorical_accuracy: 0.8607 - val_precision: 0.5674 - val_recall: 0.9325 - val_auc: 0.8920\n",
      "Epoch 63/100\n",
      "718/718 [==============================] - 1s 2ms/step - loss: 0.6749 - categorical_accuracy: 0.8405 - precision: 0.4794 - recall: 0.8415 - auc: 0.7571 - val_loss: 0.3941 - val_categorical_accuracy: 0.8620 - val_precision: 0.5782 - val_recall: 0.9356 - val_auc: 0.9129\n",
      "Epoch 64/100\n",
      "718/718 [==============================] - 2s 2ms/step - loss: 0.6830 - categorical_accuracy: 0.8418 - precision: 0.4927 - recall: 0.7862 - auc: 0.7501 - val_loss: 0.3988 - val_categorical_accuracy: 0.8572 - val_precision: 0.4935 - val_recall: 0.8309 - val_auc: 0.8200\n",
      "Epoch 65/100\n",
      "718/718 [==============================] - 2s 2ms/step - loss: 0.6750 - categorical_accuracy: 0.8426 - precision: 0.5057 - recall: 0.7841 - auc: 0.7642 - val_loss: 0.3926 - val_categorical_accuracy: 0.8619 - val_precision: 0.5216 - val_recall: 0.9367 - val_auc: 0.8940\n",
      "Epoch 66/100\n",
      "718/718 [==============================] - 2s 2ms/step - loss: 0.6774 - categorical_accuracy: 0.8423 - precision: 0.5011 - recall: 0.7999 - auc: 0.7678 - val_loss: 0.3979 - val_categorical_accuracy: 0.8585 - val_precision: 0.5438 - val_recall: 0.9008 - val_auc: 0.8791\n",
      "Epoch 67/100\n",
      "718/718 [==============================] - 2s 2ms/step - loss: 0.6808 - categorical_accuracy: 0.8409 - precision: 0.4732 - recall: 0.8448 - auc: 0.7671 - val_loss: 0.3937 - val_categorical_accuracy: 0.8622 - val_precision: 0.4764 - val_recall: 0.9524 - val_auc: 0.8779\n",
      "Epoch 68/100\n",
      "718/718 [==============================] - 1s 2ms/step - loss: 0.6693 - categorical_accuracy: 0.8426 - precision: 0.4960 - recall: 0.7947 - auc: 0.7574 - val_loss: 0.3961 - val_categorical_accuracy: 0.8632 - val_precision: 0.6276 - val_recall: 0.8546 - val_auc: 0.8898\n",
      "Epoch 69/100\n",
      "718/718 [==============================] - 2s 2ms/step - loss: 0.6635 - categorical_accuracy: 0.8430 - precision: 0.4845 - recall: 0.7853 - auc: 0.7451 - val_loss: 0.3983 - val_categorical_accuracy: 0.8619 - val_precision: 0.6468 - val_recall: 0.8787 - val_auc: 0.9017\n",
      "Epoch 70/100\n",
      "718/718 [==============================] - 2s 2ms/step - loss: 0.6701 - categorical_accuracy: 0.8440 - precision: 0.4969 - recall: 0.7789 - auc: 0.7525 - val_loss: 0.3963 - val_categorical_accuracy: 0.8626 - val_precision: 0.6088 - val_recall: 0.8533 - val_auc: 0.8787\n",
      "Epoch 71/100\n",
      "718/718 [==============================] - 2s 2ms/step - loss: 0.6642 - categorical_accuracy: 0.8436 - precision: 0.4843 - recall: 0.7808 - auc: 0.7445 - val_loss: 0.3960 - val_categorical_accuracy: 0.8628 - val_precision: 0.5469 - val_recall: 0.9272 - val_auc: 0.8962\n",
      "Epoch 72/100\n",
      "718/718 [==============================] - 2s 2ms/step - loss: 0.6669 - categorical_accuracy: 0.8444 - precision: 0.4970 - recall: 0.7318 - auc: 0.7330 - val_loss: 0.3901 - val_categorical_accuracy: 0.8600 - val_precision: 0.6215 - val_recall: 0.6821 - val_auc: 0.8068\n",
      "Epoch 73/100\n",
      "718/718 [==============================] - 2s 2ms/step - loss: 0.6632 - categorical_accuracy: 0.8451 - precision: 0.4996 - recall: 0.7588 - auc: 0.7445 - val_loss: 0.3916 - val_categorical_accuracy: 0.8647 - val_precision: 0.5928 - val_recall: 0.9179 - val_auc: 0.9065\n",
      "Epoch 74/100\n",
      "718/718 [==============================] - 1s 2ms/step - loss: 0.6641 - categorical_accuracy: 0.8436 - precision: 0.5071 - recall: 0.7405 - auc: 0.7422 - val_loss: 0.3975 - val_categorical_accuracy: 0.8581 - val_precision: 0.5462 - val_recall: 0.8394 - val_auc: 0.8423\n",
      "Epoch 75/100\n",
      "718/718 [==============================] - 2s 2ms/step - loss: 0.6609 - categorical_accuracy: 0.8455 - precision: 0.5054 - recall: 0.7300 - auc: 0.7379 - val_loss: 0.3966 - val_categorical_accuracy: 0.8630 - val_precision: 0.6091 - val_recall: 0.7611 - val_auc: 0.8381\n",
      "Epoch 76/100\n",
      "718/718 [==============================] - 2s 2ms/step - loss: 0.6782 - categorical_accuracy: 0.8443 - precision: 0.5089 - recall: 0.7229 - auc: 0.7364 - val_loss: 0.3885 - val_categorical_accuracy: 0.8626 - val_precision: 0.5958 - val_recall: 0.8094 - val_auc: 0.8509\n",
      "Epoch 77/100\n",
      "718/718 [==============================] - 2s 2ms/step - loss: 0.6665 - categorical_accuracy: 0.8453 - precision: 0.5097 - recall: 0.7261 - auc: 0.7374 - val_loss: 0.3994 - val_categorical_accuracy: 0.8604 - val_precision: 0.5783 - val_recall: 0.7944 - val_auc: 0.8351\n",
      "Epoch 78/100\n",
      "718/718 [==============================] - 2s 2ms/step - loss: 0.6600 - categorical_accuracy: 0.8453 - precision: 0.4937 - recall: 0.7286 - auc: 0.7242 - val_loss: 0.3969 - val_categorical_accuracy: 0.8645 - val_precision: 0.6323 - val_recall: 0.6618 - val_auc: 0.8086\n",
      "Epoch 79/100\n",
      "718/718 [==============================] - 1s 2ms/step - loss: 0.6673 - categorical_accuracy: 0.8436 - precision: 0.4954 - recall: 0.7477 - auc: 0.7353 - val_loss: 0.3914 - val_categorical_accuracy: 0.8636 - val_precision: 0.5373 - val_recall: 0.9214 - val_auc: 0.8869\n",
      "Epoch 80/100\n",
      "718/718 [==============================] - 2s 2ms/step - loss: 0.6619 - categorical_accuracy: 0.8444 - precision: 0.4891 - recall: 0.7608 - auc: 0.7355 - val_loss: 0.4041 - val_categorical_accuracy: 0.8625 - val_precision: 0.5432 - val_recall: 0.7991 - val_auc: 0.8279\n",
      "Epoch 81/100\n",
      "718/718 [==============================] - 2s 2ms/step - loss: 0.6643 - categorical_accuracy: 0.8457 - precision: 0.4836 - recall: 0.7490 - auc: 0.7302 - val_loss: 0.4052 - val_categorical_accuracy: 0.8590 - val_precision: 0.5017 - val_recall: 0.7447 - val_auc: 0.7938\n",
      "Epoch 82/100\n",
      "718/718 [==============================] - 2s 2ms/step - loss: 0.6590 - categorical_accuracy: 0.8445 - precision: 0.4980 - recall: 0.7154 - auc: 0.7265 - val_loss: 0.3955 - val_categorical_accuracy: 0.8599 - val_precision: 0.5616 - val_recall: 0.8223 - val_auc: 0.8472\n",
      "Epoch 83/100\n",
      "718/718 [==============================] - 2s 2ms/step - loss: 0.6636 - categorical_accuracy: 0.8451 - precision: 0.4911 - recall: 0.7170 - auc: 0.7228 - val_loss: 0.4421 - val_categorical_accuracy: 0.8607 - val_precision: 0.4925 - val_recall: 0.7834 - val_auc: 0.7973\n",
      "Epoch 84/100\n",
      "718/718 [==============================] - 2s 2ms/step - loss: 0.6638 - categorical_accuracy: 0.8449 - precision: 0.4850 - recall: 0.7552 - auc: 0.7333 - val_loss: 0.3930 - val_categorical_accuracy: 0.8640 - val_precision: 0.4947 - val_recall: 0.7912 - val_auc: 0.8039\n",
      "Epoch 85/100\n",
      "718/718 [==============================] - 1s 2ms/step - loss: 0.6626 - categorical_accuracy: 0.8445 - precision: 0.4780 - recall: 0.7780 - auc: 0.7372 - val_loss: 0.3981 - val_categorical_accuracy: 0.8628 - val_precision: 0.5414 - val_recall: 0.9028 - val_auc: 0.8845\n",
      "Epoch 86/100\n",
      "718/718 [==============================] - 1s 2ms/step - loss: 0.6562 - categorical_accuracy: 0.8466 - precision: 0.4899 - recall: 0.7493 - auc: 0.7355 - val_loss: 0.3894 - val_categorical_accuracy: 0.8597 - val_precision: 0.5431 - val_recall: 0.8208 - val_auc: 0.8417\n",
      "Epoch 87/100\n",
      "718/718 [==============================] - 2s 2ms/step - loss: 0.6742 - categorical_accuracy: 0.8436 - precision: 0.5145 - recall: 0.7089 - auc: 0.7296 - val_loss: 0.4021 - val_categorical_accuracy: 0.8632 - val_precision: 0.5718 - val_recall: 0.6534 - val_auc: 0.7809\n",
      "Epoch 88/100\n",
      "718/718 [==============================] - 2s 2ms/step - loss: 0.6633 - categorical_accuracy: 0.8450 - precision: 0.5182 - recall: 0.6977 - auc: 0.7276 - val_loss: 0.3918 - val_categorical_accuracy: 0.8636 - val_precision: 0.5164 - val_recall: 0.8293 - val_auc: 0.8111\n",
      "Epoch 89/100\n",
      "718/718 [==============================] - 2s 2ms/step - loss: 0.6699 - categorical_accuracy: 0.8435 - precision: 0.4891 - recall: 0.7423 - auc: 0.7267 - val_loss: 0.5135 - val_categorical_accuracy: 0.8623 - val_precision: 0.5265 - val_recall: 0.9404 - val_auc: 0.8954\n",
      "Epoch 90/100\n",
      "718/718 [==============================] - 2s 2ms/step - loss: 0.6645 - categorical_accuracy: 0.8426 - precision: 0.4747 - recall: 0.7988 - auc: 0.7393 - val_loss: 0.3897 - val_categorical_accuracy: 0.8628 - val_precision: 0.5737 - val_recall: 0.8711 - val_auc: 0.8803\n",
      "Epoch 91/100\n",
      "718/718 [==============================] - 1s 2ms/step - loss: 0.6716 - categorical_accuracy: 0.8433 - precision: 0.4786 - recall: 0.7756 - auc: 0.7348 - val_loss: 0.3993 - val_categorical_accuracy: 0.8635 - val_precision: 0.6182 - val_recall: 0.8590 - val_auc: 0.8886\n",
      "Epoch 92/100\n",
      "718/718 [==============================] - 2s 2ms/step - loss: 0.6612 - categorical_accuracy: 0.8436 - precision: 0.4788 - recall: 0.7717 - auc: 0.7338 - val_loss: 0.3919 - val_categorical_accuracy: 0.8609 - val_precision: 0.4774 - val_recall: 0.9413 - val_auc: 0.8773\n",
      "Epoch 93/100\n",
      "718/718 [==============================] - 2s 2ms/step - loss: 0.6726 - categorical_accuracy: 0.8442 - precision: 0.4994 - recall: 0.7215 - auc: 0.7288 - val_loss: 0.3944 - val_categorical_accuracy: 0.8603 - val_precision: 0.5554 - val_recall: 0.6476 - val_auc: 0.7521\n",
      "Epoch 94/100\n",
      "718/718 [==============================] - 2s 2ms/step - loss: 0.6638 - categorical_accuracy: 0.8455 - precision: 0.4871 - recall: 0.7186 - auc: 0.7183 - val_loss: 0.4016 - val_categorical_accuracy: 0.8608 - val_precision: 0.5579 - val_recall: 0.8184 - val_auc: 0.8294\n",
      "Epoch 95/100\n",
      "718/718 [==============================] - 2s 2ms/step - loss: 0.6637 - categorical_accuracy: 0.8466 - precision: 0.4731 - recall: 0.7634 - auc: 0.7226 - val_loss: 0.3955 - val_categorical_accuracy: 0.8585 - val_precision: 0.5233 - val_recall: 0.8772 - val_auc: 0.8554\n",
      "Epoch 96/100\n",
      "718/718 [==============================] - 2s 2ms/step - loss: 0.6589 - categorical_accuracy: 0.8450 - precision: 0.4652 - recall: 0.7733 - auc: 0.7219 - val_loss: 0.3945 - val_categorical_accuracy: 0.8631 - val_precision: 0.5239 - val_recall: 0.7898 - val_auc: 0.8222\n",
      "Epoch 97/100\n",
      "718/718 [==============================] - 2s 2ms/step - loss: 0.6652 - categorical_accuracy: 0.8451 - precision: 0.4663 - recall: 0.7680 - auc: 0.7237 - val_loss: 0.4056 - val_categorical_accuracy: 0.8585 - val_precision: 0.4436 - val_recall: 0.8441 - val_auc: 0.7945\n",
      "Epoch 98/100\n",
      "718/718 [==============================] - 1s 2ms/step - loss: 0.6646 - categorical_accuracy: 0.8446 - precision: 0.4868 - recall: 0.7244 - auc: 0.7221 - val_loss: 0.3986 - val_categorical_accuracy: 0.8560 - val_precision: 0.5732 - val_recall: 0.7820 - val_auc: 0.8285\n",
      "Epoch 99/100\n",
      "718/718 [==============================] - 2s 2ms/step - loss: 0.6599 - categorical_accuracy: 0.8446 - precision: 0.4967 - recall: 0.7159 - auc: 0.7260 - val_loss: 0.4016 - val_categorical_accuracy: 0.8613 - val_precision: 0.5725 - val_recall: 0.7357 - val_auc: 0.8162\n",
      "Epoch 100/100\n",
      "718/718 [==============================] - 2s 2ms/step - loss: 0.6605 - categorical_accuracy: 0.8449 - precision: 0.4927 - recall: 0.7183 - auc: 0.7233 - val_loss: 0.3971 - val_categorical_accuracy: 0.8606 - val_precision: 0.5570 - val_recall: 0.6915 - val_auc: 0.7825\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit"
  },
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}