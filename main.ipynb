{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the entire pipeline from downloading unscored data to finished predictions with Artificial Neural Network. These are all markdown blocks so you don't run them here because the pipeline is complete in the branch for this unscored data. To replicate, you can\n",
    "```\n",
    "mkdir ../tmp\n",
    "cp main.ipynb utils.py best_model.h5 ../tmp\n",
    "```\n",
    "and download your new data to tmp, working there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw Data\n",
    "```\n",
    "mkdir raw\n",
    "unzip data -d raw\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rename Data\n",
    "We do this because the names are annoying to work with. We create a mapping into the integers and save the mapping in a file ``mapping\". First:\n",
    "```\n",
    "mkdir renamed\n",
    "```\n",
    "then\n",
    "```\n",
    "i=0\n",
    "f = open('mapping','w+')\n",
    "for file in os.listdir(\"raw\"):\n",
    "    command = \"cp \\\"raw/\"+file+\"\\\" renamed/\"+str(i)+\".xls\"\n",
    "    f.write(file+'\\n')\n",
    "    i+=1\n",
    "    print(i)\n",
    "    print(command)\n",
    "    os.system(command)\n",
    "f.close()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess\n",
    "We want to preprocess, prettify, remove NaN, etc. First\n",
    "```\n",
    "mkdir preprocessed\n",
    "```\n",
    "then\n",
    "```\n",
    "from utils import preprocess\n",
    "for file in os.listdir(\"renamed\"):\n",
    "    preprocess(file)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Window\n",
    "As described in our manuscript, we window into 50 second epochs. First\n",
    "```\n",
    "mkdir windowed\n",
    "```\n",
    "then\n",
    "```\n",
    "from pandas import read_csv\n",
    "import pandas as pd\n",
    "from numpy import array\n",
    "from tqdm import tqdm\n",
    "# from utils import window\n",
    "for i in range(32):\n",
    "    target_filename = str(i)+\"_preprocessed\"\n",
    "    df = pd.read_csv(\"preprocessed/\"+target_filename+\".csv\")\n",
    "    Y = pd.DataFrame()\n",
    "\n",
    "    for i in tqdm(range(len(df)-4)):\n",
    "        win = df.iloc[i:i+5]\n",
    "        x = win.values.flatten()\n",
    "        X = pd.DataFrame(x).T\n",
    "        Y = pd.concat([Y,X])\n",
    "    df_win = Y\n",
    "    df_win = df_win.reset_index()\n",
    "    del df_win['index']\n",
    "    df = df_win\n",
    "    if ( not os.path.isdir('windowed')):\n",
    "        os.system('mkdir windowed')\n",
    "    target_filename = target_filename.replace(\".csv\",\"\")\n",
    "    df.to_csv(\"windowed/\"+target_filename+\"_windowed.csv\",index=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scale\n",
    "Scale data for neural network goodness. First\n",
    "```\n",
    "mkdir windowed_scaled\n",
    "```\n",
    "then \n",
    "```\n",
    "from pandas import read_csv\n",
    "import pandas as pd\n",
    "for i in range(32):\n",
    "    filename = \"windowed/\"+str(i)+\"_preprocessed_windowed.csv\"\n",
    "    X = read_csv(filename)\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    X = scaler.fit_transform(X)\n",
    "    pd.DataFrame(X).to_csv(\"windowed_scaled/\"+str(i)+\".csv\",index=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN Prediction\n",
    "Load model from best_model.h5. Predict and save. These are predictions for 50-second windows. First\n",
    "```\n",
    "mkdir predictions\n",
    "```\n",
    "then \n",
    "```\n",
    "for i in range(32):\n",
    "    filename = \"windowed_scaled/\"+str(i)+\".csv\"\n",
    "    X = read_csv(filename)\n",
    "    X = np.array(X)\n",
    "\n",
    "    from keras.models import load_model\n",
    "    model = load_model('best_model.h5')\n",
    "    import numpy as np\n",
    "    x = np.array(X)\n",
    "    y = model.predict(x)\n",
    "    y = np.array(y)\n",
    "    y = np.argmax(y,axis=1)\n",
    "    pd.DataFrame(y).to_csv(\"predictions/\"+str(i)+\".csv\",index=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expand Predictions\n",
    "Predictions are based on windowed data. We need to expand predictions to be on unwindowed data. Thus, we argmax the last 5 predictions to find the ith prediction. First\n",
    "```\n",
    "mkdir expanded_predictions\n",
    "```\n",
    "then\n",
    "```\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "for file in tqdm(os.listdir(\"predictions\")):\n",
    "    df = pd.read_csv(\"predictions/\"+file)\n",
    "    Y = np.array(df)\n",
    "    Y = Y.reshape(Y.shape[0],)\n",
    "    # print(len(Y))\n",
    "    Y_new = []\n",
    "    for i,x in tqdm(enumerate(range(len(Y)+4))):\n",
    "        if(i==0):\n",
    "            # print(\"i:\",i)\n",
    "            # print(Y[0])\n",
    "            # print(\"Bincount:\",Y[0])\n",
    "            Y_new.append(Y[0])\n",
    "        elif(i<5):\n",
    "            # print(\"i:\",i)\n",
    "            # print(Y[0:i])\n",
    "            # print(\"Bincount:\",np.bincount(Y[0:i]))\n",
    "            # print(\"Class:\",np.argmax(np.bincount(Y[0:i])))\n",
    "            Y_new.append(np.argmax(np.bincount(Y[0:i])))\n",
    "        elif(i>8635 and i!=8639):\n",
    "            # print(\"i:\",i)\n",
    "            # print(Y[8635-(4-(i-8635)):8635])\n",
    "            # print(\"Bincount:\",np.bincount(Y[8635-(4-(i-8635)):8635]))\n",
    "            # print(\"Class:\",np.argmax(np.bincount(Y[8635-(4-(i-8635)):8635])))\n",
    "            Y_new.append(np.argmax(np.bincount(Y[8635-(4-(i-8635)):8635])))\n",
    "        elif(i==8639):\n",
    "            # print(\"i:\",i)\n",
    "            # print(Y[8635])\n",
    "            # print(\"Bincount:\",Y[8365])\n",
    "            Y_new.append(Y[8365])\n",
    "        else:\n",
    "            # print(\"i:\",i)\n",
    "            # print(Y[i-4:i])\n",
    "            # print(\"Bincount:\",np.bincount(Y[i-4:i]))\n",
    "            # print(\"Class:\",np.argmax(np.bincount(Y[i-4:i])))\n",
    "            Y_new.append(np.argmax(np.bincount(Y[i-4:i])))\n",
    "    pd.DataFrame(Y_new).to_csv(\"expanded_predictions/\"+file,index=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rename Expanded Predictions\n",
    "If you want. We are done before this. First\n",
    "```\n",
    "mkdir expanded_predictions_renamed\n",
    "```\n",
    "then\n",
    "```\n",
    "i = 0\n",
    "import pandas as pd\n",
    "with open(\"mapping\") as f:\n",
    "    df = pd.read_csv(\"expanded_predictions/\"+str(i)+\".csv\")\n",
    "    for line in f:\n",
    "        print(len(line))\n",
    "        df.to_csv(\"expanded_predictions_renamed/\"+line.replace(\".xls\",\".csv\"),index=False)\n",
    "\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
